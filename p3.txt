import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# MNIST transform and loader
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=1000)

# Define CNN Architecture
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv_layer = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.fc_layer = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 5 * 5, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = self.conv_layer(x)
        x = self.fc_layer(x)
        return x

# Train the CNN
model = CNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(5):
    total_loss = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {total_loss:.4f}")

# Evaluate the Model on Test Data
correct = 0
total = 0
model.eval()
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Accuracy on test set: {100 * correct / total:.2f}%")

# Visualize Predictions (Optional)
images, labels = next(iter(test_loader))
images = images[:6]
labels = labels[:6]
outputs = model(images.to(device))
_, preds = torch.max(outputs, 1)

plt.figure(figsize=(10, 2))
for i in range(6):import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
# Step 2: Data preprocessing & loading
transform = transforms.Compose([
transforms.ToTensor(), # convert to tensor
transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalize
])
batch_size = 32
# Load CIFAR-10 dataset
trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
shuffle=True, num_workers=2)
testset = torchvision.datasets.CIFAR10(root='./data', train=False,
download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
shuffle=False, num_workers=2)
classes = ('plane', 'car', 'bird', 'cat', 'deer',
'dog', 'frog', 'horse', 'ship', 'truck')
# Step 3: Define CNN model
class CNN(nn.Module):
def __init__(self):
super(CNN, self).__init__()
# Convolutional layers
self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # input=3 channels, output=32
self.pool = nn.MaxPool2d(2, 2)
self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
# Fully connected layers
self.fc1 = nn.Linear(64 * 8 * 8, 128) # 64 filters, 8x8 feature maps
self.fc2 = nn.Linear(128, 10) # 10 classes in CIFAR-10
def forward(self, x):
x = self.pool(F.relu(self.conv1(x))) # conv1 + relu + pool
x = self.pool(F.relu(self.conv2(x))) # conv2 + relu + pool
x = x.view(-1, 64 * 8 * 8) # flatten
x = F.relu(self.fc1(x)) # fully connected 1
x = self.fc2(x) # fully connected 2
return x
net = CNN()
# Step 4: Define loss function & optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.001)
# Step 5: Training the CNN
for epoch in range(5): # loop over dataset multiple times
running_loss = 0.0
for i, data in enumerate(trainloader, 0):
inputs, labels = data
optimizer.zero_grad() # zero the parameter gradients
outputs = net(inputs) # forward
loss = criterion(outputs, labels)
loss.backward() # backward
optimizer.step() # optimize
running_loss += loss.item()
if i % 200 == 199: # print every 200 mini-batches
print(f"[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}")
running_loss = 0.0
print("Finished Training")
[1, 200] loss: 1.772
[1, 400] loss: 1.431
[1, 600] loss: 1.316
[1, 800] loss: 1.209
[1, 1000] loss: 1.152
[1, 1200] loss: 1.097
[1, 1400] loss: 1.051
[2, 200] loss: 0.959
[2, 400] loss: 0.932
[2, 600] loss: 0.918
[2, 800] loss: 0.876
[2, 1000] loss: 0.905
[2, 1200] loss: 0.873
[2, 1400] loss: 0.889
[3, 200] loss: 0.712
[3, 400] loss: 0.733
[3, 600] loss: 0.750
[3, 800] loss: 0.744
[3, 1000] loss: 0.728
[3, 1200] loss: 0.751
[3, 1400] loss: 0.742
[4, 200] loss: 0.586
[4, 400] loss: 0.618
[4, 600] loss: 0.599
[4, 800] loss: 0.616
[4, 1000] loss: 0.636
[4, 1200] loss: 0.618
[4, 1400] loss: 0.619
[5, 200] loss: 0.466
[5, 400] loss: 0.464
[5, 600] loss: 0.508
[5, 800] loss: 0.492
[5, 1000] loss: 0.521
[5, 1200] loss: 0.521
[5, 1400] loss: 0.523
Finished Training
# Step 6: Test accuracy
correct, total = 0, 0
with torch.no_grad():
for data in testloader:
images, labels = data
outputs = net(images)
_, predicted = torch.max(outputs, 1)
total += labels.size(0)
correct += (predicted == labels).sum().item()
print(f"Accuracy on 10000 test images: {100 * correct / total:.2f}%")
    plt.subplot(1, 6, i + 1)
    plt.imshow(images[i].squeeze(), cmap='gray')
    plt.title(f"Pred: {preds[i].item()}")
    plt.axis('off')
plt.tight_layout()
plt.show()
